import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import threading
import os
import logging
from tkinter import font
import tkinter.ttk as ttk
import librosa
import numpy as np
import pandas as pd
import joblib
import os
import threading
from sklearn.cluster import KMeans
from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
from os import listdir
from os.path import isfile, join
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
import queue
import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA
from os import listdir
from os.path import isfile, join
import os
import sys

simple_emotion_map = {
        0: "æ‚²ä¼¤/å¿§éƒ/å­¤ç‹¬",
        1: "æ„‰æ‚¦/æ¬¢å¿«/æ”¾æ¾", 
        2: "å¦ç±»/å®éªŒæ€§/å¤±çœŸ" # æŠ½è±¡
    }
def resource_path(relative_path):
    """ å¤„ç†æ‰“åŒ…åçš„èµ„æºè·¯å¾„ """
    if hasattr(sys, '_MEIPASS'):
        base_path = sys._MEIPASS
    else:
        base_path = os.path.abspath(".")
    return os.path.join(base_path, relative_path)


def predict(mp3_paths):
    print(f"æ­£åœ¨å¤„ç†æ­Œæ›²ï¼š{mp3_paths}")
    features, valid_paths = parallel_feature_extraction(mp3_paths)
    
    if not features:
        raise ValueError("æ²¡æœ‰æœ‰æ•ˆçš„æ­Œæ›²ç‰¹å¾å¯åˆ†æ")
    
    # è½¬æ¢ä¸ºDataFrame
    feature_df = pd.DataFrame(features, columns=KEY_FEATURE_NAMES)
    
    # ç‰¹å¾å½’ä¸€åŒ–
    scaler = MinMaxScaler()
    scaled_features = scaler.fit_transform(feature_df)
    
    # åŠ è½½æ¨¡å‹å¹¶é¢„æµ‹
    kmeans = load_or_create_kmeans_model(
        n_clusters=4,
        model_path=resource_path("music_kmeans_model.pkl")  # å…³é”®ä¿®æ”¹
    )
    cluster_labels = kmeans.predict(scaled_features)
    
    for i, label in enumerate(cluster_labels):
        print(f"æ­Œæ›²ï¼š{valid_paths[i]}ï¼Œèšç±»æ ‡ç­¾ï¼š{label},æƒ…æ„Ÿå«ä¹‰ä¸º{simple_emotion_map[label]}")

    return valid_paths, cluster_labels

def get_mp3_files(path):
    """è·å–ç›®å½•ä¸‹æ‰€æœ‰MP3æ–‡ä»¶"""
    return [f for f in listdir(path) 
            if isfile(join(path, f)) and f.lower().endswith('.mp3')]



# ç²¾é€‰çš„15ä¸ªå…³é”®ç‰¹å¾åç§°
KEY_FEATURE_NAMES = [
    'tempo',
    'chroma_stft_mean',
    'mfcc_mean',
    'zcr_mean',
    'spectral_centroid_mean',
    'rmse_mean',
    'spectral_bandwidth_mean',
    'chroma_cq_mean',
    'mfcc_delta_mean',
    'harmonic_mean',
    'percussive_mean',
    'spectral_rolloff_mean',
    'spectral_contrast_mean',
    'tonnetz_mean',
    'poly_mean'
]

# å…¨å±€é”ç”¨äºçº¿ç¨‹å®‰å…¨åœ°æ›´æ–°å…±äº«å˜é‡
print_lock = threading.Lock()

def extract_key_features(song_path):
    """æå–15ä¸ªå…³é”®ç‰¹å¾"""
    try:
        y, sr = librosa.load(song_path, duration=150)
        S = np.abs(librosa.stft(y))
        
        # æå–åŸºç¡€ç‰¹å¾
        tempo, _ = librosa.beat.beat_track(y=y, sr=sr)
        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)
        mfcc = librosa.feature.mfcc(y=y, sr=sr)
        zcr = librosa.feature.zero_crossing_rate(y)
        cent = librosa.feature.spectral_centroid(y=y, sr=sr)
        rmse = librosa.feature.rms(y=y)
        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)
        chroma_cq = librosa.feature.chroma_cqt(y=y, sr=sr)
        mfcc_delta = librosa.feature.delta(mfcc)
        harmonic = librosa.effects.harmonic(y)
        percussive = librosa.effects.percussive(y)
        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)
        contrast = librosa.feature.spectral_contrast(S=S, sr=sr)
        tonnetz = librosa.feature.tonnetz(y=y, sr=sr)
        poly = librosa.feature.poly_features(S=S, sr=sr)
        
        # ç»„ç»‡å…³é”®ç‰¹å¾
        key_features = [
            tempo,
            np.mean(chroma_stft),
            np.mean(mfcc),
            np.mean(zcr),
            np.mean(cent),
            np.mean(rmse),
            np.mean(spec_bw),
            np.mean(chroma_cq),
            np.mean(mfcc_delta),
            np.mean(harmonic),
            np.mean(percussive),
            np.mean(rolloff),
            np.mean(contrast),
            np.mean(tonnetz),
            np.mean(poly)
        ]
        
        return (song_path, key_features, None)
    except Exception as e:
        return (song_path, None, str(e))

def parallel_feature_extraction(song_paths, max_workers=None):
    """ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œæå–ç‰¹å¾"""
    if max_workers is None:
        # é»˜è®¤ä½¿ç”¨CPUæ ¸å¿ƒæ•°*2çš„çº¿ç¨‹æ•°
        max_workers = min(16, (os.cpu_count() or 1) * 1)
    
    features = []
    valid_paths = []
    failed_files = []
    
    # ä½¿ç”¨é˜Ÿåˆ—çº¿ç¨‹å®‰å…¨åœ°æ”¶é›†ç»“æœ
    result_queue = queue.Queue()
    
    def worker(path):
        try:
            result = extract_key_features(path)
            result_queue.put(result)
        except Exception as e:
            result_queue.put((path, None, str(e)))
    
    print(f"å¼€å§‹å¹¶è¡Œæå–ç‰¹å¾ (ä½¿ç”¨ {max_workers} ä¸ªçº¿ç¨‹)...")
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        futures = {executor.submit(worker, path): path for path in song_paths}
        
        # ä½¿ç”¨tqdmæ˜¾ç¤ºè¿›åº¦
        with tqdm(total=len(song_paths), desc="å¤„ç†è¿›åº¦") as pbar:
            for future in as_completed(futures):
                path, feat, error = result_queue.get()
                if feat is not None:
                    features.append(feat)
                    valid_paths.append(path)
                else:
                    failed_files.append((os.path.basename(path), error))
                pbar.update(1)
    
    if failed_files:
        with print_lock:
            print("\nå¤„ç†å¤±è´¥çš„æ–‡ä»¶:")
            for filename, error in failed_files:
                print(f"{filename}: {error}")
    
    return features, valid_paths

def load_or_create_kmeans_model(n_clusters, model_path=None):
    """åŠ è½½æˆ–åˆ›å»ºK-Meansæ¨¡å‹"""
    if model_path and os.path.exists(model_path):
        print(f"åŠ è½½ç°æœ‰æ¨¡å‹: {model_path}")
        return joblib.load(model_path)
    else:
        print(f"åˆ›å»ºæ–°çš„K-Meansæ¨¡å‹ï¼Œèšç±»æ•°={n_clusters}")
        return KMeans(n_clusters=n_clusters, random_state=42)

def visualize_clusters(feature_df, labels):
    """Visualize clustering results"""
    try:
        # Reduce dimensions to 2D using PCA
        pca = PCA(n_components=2)
        reduced_features = pca.fit_transform(feature_df)
        
        plt.figure(figsize=(12, 8))
        scatter = plt.scatter(reduced_features[:, 0], reduced_features[:, 1], 
                            c=labels, cmap='viridis', alpha=0.6, s=80)
        plt.colorbar(scatter, label='Cluster Label')
        plt.title("Music Emotion Clustering Visualization (PCA Reduced)", fontsize=14)
        plt.xlabel("Principal Component 1", fontsize=12)
        plt.ylabel("Principal Component 2", fontsize=12)
        plt.grid(True, linestyle='--', alpha=0.6)
        
        # Save visualization
        plt.savefig('music_clusters_visualization.png', dpi=300, bbox_inches='tight')
        print("Cluster visualization saved as music_clusters_visualization.png")
        plt.show()
        
    except Exception as e:
        print(f"Visualization failed: {str(e)}")

def plot_feature_importance(cluster_centers, feature_names):
    """Plot feature importance for each cluster center"""
    plt.figure(figsize=(15, 8))
    for i, center in enumerate(cluster_centers):
        plt.subplot(2, 2, i+1)
        pd.Series(center, index=feature_names).plot(kind='bar', color='skyblue')
        plt.title(f'Cluster {i} Center Feature Values', fontsize=12)
        plt.xticks(rotation=45, ha='right')
        plt.grid(axis='y', linestyle='--', alpha=0.6)
    plt.tight_layout()
    plt.savefig('cluster_features_importance.png', dpi=300, bbox_inches='tight')
    plt.show()


# def visualize_clusters(feature_df, labels):
#     """èšç±»ç»“æœå¯è§†åŒ–"""
#     try:
#         # ä½¿ç”¨PCAé™ç»´åˆ°2D
#         pca = PCA(n_components=2)
#         reduced_features = pca.fit_transform(feature_df)
        
#         plt.figure(figsize=(12, 8))
#         scatter = plt.scatter(reduced_features[:, 0], reduced_features[:, 1], 
#                             c=labels, cmap='viridis', alpha=0.6, s=80)
#         plt.colorbar(scatter, label='èšç±»æ ‡ç­¾')
#         plt.title("éŸ³ä¹æƒ…æ„Ÿèšç±»å¯è§†åŒ– (åŸºäºPCAé™ç»´)", fontsize=14)
#         plt.xlabel("ä¸»æˆåˆ†1", fontsize=12)
#         plt.ylabel("ä¸»æˆåˆ†2", fontsize=12)
#         plt.grid(True, linestyle='--', alpha=0.6)
        
#         # ä¿å­˜å¯è§†åŒ–å›¾åƒ
#         plt.savefig('music_clusters_visualization.png', dpi=300, bbox_inches='tight')
#         print("èšç±»å¯è§†åŒ–å›¾å·²ä¿å­˜ä¸º music_clusters_visualization.png")
#         plt.show()
        
#     except Exception as e:
#         print(f"å¯è§†åŒ–å¤±è´¥: {str(e)}")

# def plot_feature_importance(cluster_centers, feature_names):
#     """ç»˜åˆ¶å„èšç±»ä¸­å¿ƒçš„ç‰¹å¾é‡è¦æ€§"""
#     plt.figure(figsize=(15, 8))
#     for i, center in enumerate(cluster_centers):
#         plt.subplot(2, 2, i+1)
#         pd.Series(center, index=feature_names).plot(kind='bar', color='skyblue')
#         plt.title(f'èšç±» {i} ä¸­å¿ƒç‰¹å¾å€¼', fontsize=12)
#         plt.xticks(rotation=45, ha='right')
#         plt.grid(axis='y', linestyle='--', alpha=0.6)
#     plt.tight_layout()
#     plt.savefig('cluster_features_importance.png', dpi=300, bbox_inches='tight')
#     plt.show()

def cluster_songs(song_paths, n_clusters=3, model_path=None, max_workers=None):
    """
    ä½¿ç”¨K-Meanså¯¹æ­Œæ›²è¿›è¡Œèšç±»åˆ†æ
    
    å‚æ•°:
        song_paths (list): æ­Œæ›²æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        n_clusters (int): èšç±»æ•°é‡ï¼Œé»˜è®¤ä¸º4
        model_path (str, optional): æ¨¡å‹ä¿å­˜è·¯å¾„
        max_workers (int, optional): æœ€å¤§çº¿ç¨‹æ•°
        
    è¿”å›:
        dict: åŒ…å«èšç±»ç»“æœå’Œç‰¹å¾çš„å­—å…¸
    """
    # 1. å¹¶è¡Œæå–æ‰€æœ‰æ­Œæ›²çš„å…³é”®ç‰¹å¾
    features, valid_paths = parallel_feature_extraction(song_paths, max_workers)
    
    if not features:
        raise ValueError("æ²¡æœ‰æœ‰æ•ˆçš„æ­Œæ›²ç‰¹å¾å¯åˆ†æ")
    
    # 2. è½¬æ¢ä¸ºDataFrame
    feature_df = pd.DataFrame(features, columns=KEY_FEATURE_NAMES)
    
    # 3. ç‰¹å¾å½’ä¸€åŒ–
    print("æ­£åœ¨è¿›è¡Œç‰¹å¾å½’ä¸€åŒ–...")
    scaler = MinMaxScaler()
    scaled_features = scaler.fit_transform(feature_df)
    
    # 4. åŠ è½½æˆ–åˆ›å»ºK-Meansæ¨¡å‹
    kmeans = load_or_create_kmeans_model(n_clusters, model_path)
    
    # 5. è®­ç»ƒæ¨¡å‹(å¦‚æœæ²¡æœ‰é¢„è®­ç»ƒæ¨¡å‹)æˆ–é¢„æµ‹èšç±»
    if not model_path or not os.path.exists(model_path):
        print("è®­ç»ƒK-Meansæ¨¡å‹ä¸­...")
        kmeans.fit(scaled_features)
        if model_path:  # å¦‚æœæä¾›äº†ä¿å­˜è·¯å¾„
            joblib.dump(kmeans, model_path)
            print(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
    else:
        print("ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œèšç±»")
    
    # 6. é¢„æµ‹èšç±»æ ‡ç­¾
    print("è¿›è¡Œèšç±»é¢„æµ‹...")
    cluster_labels = kmeans.predict(scaled_features)
    
    # 7. å¯è§†åŒ–
    print("ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    visualize_clusters(feature_df, cluster_labels)
    
    # 8. åˆ†æèšç±»ä¸­å¿ƒç‰¹å¾
    cluster_centers = kmeans.cluster_centers_
    cluster_features = pd.DataFrame(scaler.inverse_transform(cluster_centers), 
                                  columns=KEY_FEATURE_NAMES)
    
    # 9. ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§
    plot_feature_importance(cluster_centers, KEY_FEATURE_NAMES)
    
    return {
        'song_paths': valid_paths,
        'features': feature_df,
        'cluster_labels': cluster_labels,
        'model': kmeans,
        'cluster_features': cluster_features,
        'scaler': scaler
    }

def interpret_clusters(cluster_features):
    """è§£é‡Šèšç±»ç»“æœçš„æƒ…æ„Ÿå«ä¹‰"""
    interpretations = []
    for i, row in cluster_features.iterrows():
        tempo = row['tempo']
        centroid = row['spectral_centroid_mean']
        zcr = row['zcr_mean']
        
        # if tempo > 120 and centroid > 2000 and zcr > 0.1:
        #     emotion = "å¿«ä¹/æ¬¢å¿«"
        # elif tempo < 90 and centroid < 1500 and zcr < 0.05:
        #     emotion = "æ‚²ä¼¤/å¿§éƒ"
        # elif tempo > 140 and zcr > 0.15:
        #     emotion = "æ„¤æ€’/æ¿€çƒˆ"
        # else:
        #     emotion = "å¹³é™/æ”¾æ¾"
            
        interpretations.append({
            'cluster': i,
            # 'emotion': emotion,
            'tempo': tempo,
            'spectral_centroid': centroid,
            'zcr': zcr
        })
    
    return pd.DataFrame(interpretations)

# def get_mp3_files(path):
#     """è·å–ç›®å½•ä¸‹æ‰€æœ‰MP3æ–‡ä»¶"""
#     return [f for f in listdir(path) 
#             if isfile(join(path, f)) and f.lower().endswith('.mp3')]




class MusicEmotionClassifierUI:
    def __init__(self, master):
        self.master = master
        master.title("éŸ³ä¹æƒ…æ„Ÿåˆ†æç³»ç»Ÿ")
        master.geometry("1000x900")
        master.configure(bg='#F0F3F5')

        self.style = ttk.Style()
        self.style.theme_use('clam')

        # è‡ªå®šä¹‰é¢œè‰²æ–¹æ¡ˆ
        self.style.configure('TFrame', background='#F0F3F5')
        self.style.configure('TLabelFrame', background='#F0F3F5', foreground='#2D3436',
                             font=('å¾®è½¯é›…é»‘', 10, 'bold'), relief='flat')
        self.style.configure('TButton', font=('å¾®è½¯é›…é»‘', 10), padding=6)
        self.style.map('TButton',
                       foreground=[('active', '#FFFFFF'), ('!active', '#2D3436')],
                       background=[('active', '#0984E3'), ('!active', '#74B9FF')])

        # Treeviewæ ·å¼
        self.style.configure('Treeview',
                             font=('å¾®è½¯é›…é»‘', 10),
                             rowheight=25,
                             background='#FFFFFF',
                             fieldbackground='#FFFFFF')
        self.style.map('Treeview', background=[('selected', '#74B9FF')])

        # è¿›åº¦æ¡æ ·å¼
        self.style.configure("custom.Horizontal.TProgressbar",
                             troughcolor='#DFE6E9',
                             background='#00B894',
                             thickness=20)

        self.results = {emotion: [] for emotion in simple_emotion_map.values()}
        self.create_widgets()
        #logging.basicConfig(filename='app.log', level=logging.ERROR)
        self.logger = logging.getLogger('MusicEmotion')
        self.logger.setLevel(logging.DEBUG)

        # åˆ›å»ºæ–‡ä»¶å¤„ç†å™¨
        try:
            fh = logging.FileHandler(resource_path('app.log'), mode='w', encoding='utf-8')
        except Exception as e:
            # è‹¥æ— æ³•åˆ›å»ºæ—¥å¿—æ–‡ä»¶åˆ™å¯ç”¨å¤‡ç”¨æ§åˆ¶å°æ—¥å¿—
            fh = logging.StreamHandler()
            self.logger.warning(f"æ— æ³•åˆ›å»ºæ—¥å¿—æ–‡ä»¶: {str(e)}")

        # æ ¼å¼è®¾ç½®
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        fh.setFormatter(formatter)
        self.logger.addHandler(fh)

    def create_widgets(self):
        # æ–‡ä»¶æ“ä½œåŒºåŸŸ - ä½¿ç”¨æ–°çš„å¸ƒå±€ç»“æ„
        header_frame = ttk.Frame(self.master)
        header_frame.pack(pady=20, padx=20, fill='x')

        control_panel = ttk.Frame(header_frame)
        control_panel.pack(side='left', fill='y')

        # ä½¿ç”¨ç°ä»£å›¾æ ‡é£æ ¼æŒ‰é’®
        self.btn_add = ttk.Button(control_panel, text="â• æ·»åŠ æ–‡ä»¶", command=self.add_files, style='TButton')
        self.btn_add.pack(side='left', padx=5)

        self.btn_clear = ttk.Button(control_panel, text="ğŸ—‘ï¸ æ¸…ç©ºåˆ—è¡¨", command=self.clear_list)
        self.btn_clear.pack(side='left', padx=5)

        # æ–‡ä»¶åˆ—è¡¨å®¹å™¨
        list_container = ttk.LabelFrame(self.master, text="å¾…åˆ†ææ–‡ä»¶åˆ—è¡¨")
        list_container.pack(pady=10, padx=20, fill='both', expand=True)

        # æ–‡ä»¶åˆ—è¡¨æ ·å¼ä¼˜åŒ–
        self.listbox = tk.Listbox(list_container,
                                  selectmode=tk.EXTENDED,
                                  bg='#FFFFFF',
                                  font=('å¾®è½¯é›…é»‘', 10),
                                  relief='flat',
                                  highlightthickness=0)
        self.listbox.pack(fill='both', expand=True, padx=5, pady=5)

        # åˆ†ææ§åˆ¶é¢æ¿
        analysis_control = ttk.Frame(self.master)
        analysis_control.pack(pady=15, padx=20, fill='x')

        self.btn_analyze = ttk.Button(analysis_control, text="ğŸ” å¼€å§‹åˆ†æ", command=self.start_analysis)
        self.btn_analyze.pack(side='left')

        self.progress = ttk.Progressbar(analysis_control,
                                        style="custom.Horizontal.TProgressbar",
                                        mode="determinate")
        self.progress.pack(side='left', padx=10, fill='x', expand=True)

        self.btn_export = ttk.Button(analysis_control, text="ğŸ“¤ å¯¼å‡ºç»“æœ",
                                     command=self.export_results, state="disabled")
        self.btn_export.pack(side='left')

        # ç»“æœå±•ç¤ºä¼˜åŒ–
        result_frame = ttk.LabelFrame(self.master, text="åˆ†æç»“æœ")
        result_frame.pack(pady=10, padx=20, fill='both', expand=True)

        # ä¼˜åŒ–Treeviewåˆ—é…ç½®
        self.tree = ttk.Treeview(result_frame,
                                 columns=("emotion", "count", "files"),
                                 show="headings",
                                 style='Treeview')

        # è®¾ç½®åˆ—æ ·å¼
        tree_font = font.Font(family='å¾®è½¯é›…é»‘', size=10)
        self.tree.tag_configure('evenrow', background='#F8F9FA')
        self.tree.tag_configure('oddrow', background='#FFFFFF')

        self.tree.heading("emotion", text="æƒ…æ„Ÿåˆ†ç±»", anchor="w")
        self.tree.heading("count", text="æ–‡ä»¶æ•°é‡", anchor="center")
        self.tree.heading("files", text="æ–‡ä»¶åˆ—è¡¨", anchor="w")

        self.tree.column("emotion", width=200, minwidth=150, anchor="w")
        self.tree.column("count", width=120, minwidth=100, anchor="center")
        self.tree.column("files", width=700, minwidth=500, anchor="w")

        # æ»šåŠ¨æ¡æ ·å¼
        vsb = ttk.Scrollbar(result_frame, orient="vertical", command=self.tree.yview)
        hsb = ttk.Scrollbar(result_frame, orient="horizontal", command=self.tree.xview)
        self.tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)

        # ç½‘æ ¼å¸ƒå±€
        self.tree.grid(row=0, column=0, sticky="nsew")
        vsb.grid(row=0, column=1, sticky="ns")
        hsb.grid(row=1, column=0, sticky="ew")

        result_frame.grid_rowconfigure(0, weight=1)
        result_frame.grid_columnconfigure(0, weight=1)

        # æ·»åŠ çŠ¶æ€æ 
        self.status_bar = ttk.Label(self.master,
                                    text="å°±ç»ª",
                                    anchor='w',
                                    font=('å¾®è½¯é›…é»‘', 9),
                                    background='#DFE6E9',
                                    foreground='#2D3436')
        self.status_bar.pack(side='bottom', fill='x')

    def add_files(self):
        files = filedialog.askopenfilenames(
            title="é€‰æ‹©éŸ³ä¹æ–‡ä»¶",
            filetypes=[("MP3æ–‡ä»¶", "*.mp3"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")]
        )
        for f in files:
            if f not in self.listbox.get(0, tk.END):
                self.listbox.insert(tk.END, f)

    def clear_list(self):
        self.listbox.delete(0, tk.END)
        self.tree.delete(*self.tree.get_children())
        for emotion in self.results:
            self.results[emotion].clear()
        self.btn_export.config(state="disabled")

    def start_analysis(self):
        files = self.listbox.get(0, tk.END)
        if not files:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆæ·»åŠ è¦åˆ†æçš„MP3æ–‡ä»¶ï¼")
            return

        self.btn_analyze.config(state="disabled")
        self.btn_export.config(state="disabled")
        self.progress["value"] = 0
        self.progress["maximum"] = len(files)

        threading.Thread(
            target=self.analyze_files,
            args=(files,),
            daemon=True
        ).start()

    def analyze_files(self, files):
        try:
            valid_paths, predictions = predict(files)

            # æ¸…ç©ºç»“æœ
            for emotion in self.results:
                self.results[emotion].clear()

            # å¤„ç†æœ‰æ•ˆæ–‡ä»¶
            for idx, (file_path, label) in enumerate(zip(valid_paths, predictions)):
                try:
                    emotion = simple_emotion_map[label]
                    filename = os.path.basename(file_path)
                    self.results[emotion].append(filename)
                except Exception as e:
                    logging.error(f"æ–‡ä»¶å¤„ç†å¤±è´¥ï¼š{file_path}\n{str(e)}")
                self.master.after(10, self.update_progress, idx + 1)

            # å¤„ç†æ— æ•ˆæ–‡ä»¶
            invalid_files = set(files) - set(valid_paths)
            if invalid_files:
                self.master.after(10, lambda: messagebox.showwarning(
                    "éƒ¨åˆ†æ–‡ä»¶æ— æ•ˆ",
                    f"ä»¥ä¸‹æ–‡ä»¶æ— æ³•åˆ†æï¼ˆè¯·ç¡®ä¿æ—¶é•¿â‰¥150ç§’ï¼‰ï¼š\n" + "\n".join(os.path.basename(f) for f in invalid_files)
                ))

            self.master.after(10, self.display_results)

        except ValueError as ve:
            self.master.after(10, lambda: messagebox.showerror("é”™è¯¯", str(ve)))
        except Exception as e:
            #logging.error(f"åˆ†æè¿‡ç¨‹å‡ºé”™ï¼š{str(e)}")
            if hasattr(self, 'logger') and self.logger:
                self.logger.error(f"åˆ†æè¿‡ç¨‹å‡ºé”™ï¼š{str(e)}")
            else:
                print(f"åˆ†æè¿‡ç¨‹å‡ºé”™ï¼ˆæ—¥å¿—ä¸å¯ç”¨ï¼‰ï¼š{str(e)}")  # å¤‡ç”¨è¾“å‡º
            self.master.after(10, lambda: messagebox.showerror("é”™è¯¯", f"åˆ†æå¤±è´¥ï¼š{str(e)}"))
        finally:
            self.master.after(10, lambda: self.btn_analyze.config(state="normal"))

    def update_progress(self, value):
        self.progress["value"] = value
        self.status_bar.config(text=f"å¤„ç†è¿›åº¦ï¼š{value}/{len(self.listbox.get(0, tk.END))}")
        self.master.update_idletasks()

    def display_results(self):
        self.tree.delete(*self.tree.get_children())
        for emotion, files in self.results.items():
            if files:
                # åœ¨ UI ä¸­æ˜¾ç¤ºæƒ…æ„Ÿåˆ†ç±»ã€æ–‡ä»¶æ•°é‡å’Œæ–‡ä»¶åˆ—è¡¨
                self.tree.insert("", "end", values=(
                    emotion,
                    len(files),
                    "\n".join(files)
                ))
        self.btn_export.config(state="normal")

    def export_results(self):
        output_path = filedialog.asksaveasfilename(
            defaultextension=".txt",
            filetypes=[("æ–‡æœ¬æ–‡ä»¶", "*.txt")]
        )
        if not output_path:
            return

        try:
            with open(output_path, "w", encoding="utf-8") as f:
                for emotion, files in self.results.items():
                    if files:
                        f.write(f"ã€{emotion}ã€‘å…±{len(files)}ä¸ªæ–‡ä»¶ï¼š\n")
                        f.write("\n".join(f" - {name}" for name in files))
                        f.write("\n\n")

            messagebox.showinfo("å¯¼å‡ºæˆåŠŸ", f"ç»“æœå·²ä¿å­˜åˆ°ï¼š\n{output_path}")
            os.startfile(output_path)
        except Exception as e:
            # å¢åŠ æ—¥å¿—å™¨æ£€æŸ¥
            if hasattr(self, 'logger') and self.logger:
                self.logger.exception("å¯¼å‡ºç»“æœå¤±è´¥")  # ä¼šè‡ªåŠ¨è®°å½•å †æ ˆ
            else:
                traceback.print_exc()  # å½“æ—¥å¿—ä¸å¯ç”¨æ—¶æ‰“å°åˆ°æ§åˆ¶å°
            messagebox.showerror("å¯¼å‡ºå¤±è´¥", str(e))


if __name__ == "__main__":
    root = tk.Tk()
    app = MusicEmotionClassifierUI(root)
    root.mainloop()